{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50643f65",
   "metadata": {},
   "source": [
    "# NLP_Tp1_Spacy_Arabic\n",
    "\n",
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb35167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.ar import *\n",
    "\n",
    "nlp = Arabic()\n",
    "txt=nlp(\"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر، و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة، الجبر كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا. و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06a4df",
   "metadata": {},
   "source": [
    "# Tokenazition and pos tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7b84b03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ربما\n",
      "\n",
      "\n",
      "كانت\n",
      "\n",
      "\n",
      "أحد\n",
      "\n",
      "\n",
      "أهم\n",
      "\n",
      "\n",
      "التطورات\n",
      "\n",
      "\n",
      "التي\n",
      "\n",
      "\n",
      "قامت\n",
      "\n",
      "\n",
      "بها\n",
      "\n",
      "\n",
      "الرياضيات\n",
      "\n",
      "\n",
      "العربية\n",
      "\n",
      "\n",
      "التي\n",
      "\n",
      "\n",
      "بدأت\n",
      "\n",
      "\n",
      "في\n",
      "\n",
      "\n",
      "هذا\n",
      "\n",
      "\n",
      "الوقت\n",
      "\n",
      "\n",
      "بعمل\n",
      "\n",
      "\n",
      "الخوارزمي\n",
      "\n",
      "\n",
      "و\n",
      "\n",
      "\n",
      "هي\n",
      "\n",
      "\n",
      "بدايات\n",
      "\n",
      "\n",
      "الجبر\n",
      "\n",
      "\n",
      "،\n",
      "\n",
      "\n",
      "و\n",
      "\n",
      "\n",
      "من\n",
      "\n",
      "\n",
      "المهم\n",
      "\n",
      "\n",
      "فهم\n",
      "\n",
      "\n",
      "كيف\n",
      "\n",
      "\n",
      "كانت\n",
      "\n",
      "\n",
      "هذه\n",
      "\n",
      "\n",
      "الفكرة\n",
      "\n",
      "\n",
      "الجديدة\n",
      "\n",
      "\n",
      "مهمة\n",
      "\n",
      "\n",
      "،\n",
      "\n",
      "\n",
      "فقد\n",
      "\n",
      "\n",
      "كانت\n",
      "\n",
      "\n",
      "خطوة\n",
      "\n",
      "\n",
      "ثورية\n",
      "\n",
      "\n",
      "بعيدا\n",
      "\n",
      "\n",
      "عن\n",
      "\n",
      "\n",
      "المفهوم\n",
      "\n",
      "\n",
      "اليوناني\n",
      "\n",
      "\n",
      "للرياضيات\n",
      "\n",
      "\n",
      "التي\n",
      "\n",
      "\n",
      "هي\n",
      "\n",
      "\n",
      "في\n",
      "\n",
      "\n",
      "جوهرها\n",
      "\n",
      "\n",
      "هندسة\n",
      "\n",
      "\n",
      "،\n",
      "\n",
      "\n",
      "الجبر\n",
      "\n",
      "\n",
      "كان\n",
      "\n",
      "\n",
      "نظرية\n",
      "\n",
      "\n",
      "موحدة\n",
      "\n",
      "\n",
      "تتيح\n",
      "\n",
      "\n",
      "الأعداد\n",
      "\n",
      "\n",
      "الكسرية\n",
      "\n",
      "\n",
      "و\n",
      "\n",
      "\n",
      "الأعداد\n",
      "\n",
      "\n",
      "اللا\n",
      "\n",
      "\n",
      "كسرية\n",
      "\n",
      "\n",
      "،\n",
      "\n",
      "\n",
      "و\n",
      "\n",
      "\n",
      "قدم\n",
      "\n",
      "\n",
      "وسيلة\n",
      "\n",
      "\n",
      "للتنمية\n",
      "\n",
      "\n",
      "في\n",
      "\n",
      "\n",
      "هذا\n",
      "\n",
      "\n",
      "الموضوع\n",
      "\n",
      "\n",
      "مستقبلا\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "و\n",
      "\n",
      "\n",
      "جانب\n",
      "\n",
      "\n",
      "آخر\n",
      "\n",
      "\n",
      "مهم\n",
      "\n",
      "\n",
      "لإدخال\n",
      "\n",
      "\n",
      "أفكار\n",
      "\n",
      "\n",
      "الجبر\n",
      "\n",
      "\n",
      "و\n",
      "\n",
      "\n",
      "هو\n",
      "\n",
      "\n",
      "أنه\n",
      "\n",
      "\n",
      "سمح\n",
      "\n",
      "\n",
      "بتطبيق\n",
      "\n",
      "\n",
      "الرياضيات\n",
      "\n",
      "\n",
      "على\n",
      "\n",
      "\n",
      "نفسها\n",
      "\n",
      "\n",
      "بطريقة\n",
      "\n",
      "\n",
      "لم\n",
      "\n",
      "\n",
      "تحدث\n",
      "\n",
      "\n",
      "من\n",
      "\n",
      "\n",
      "قبل\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tok in txt:\n",
    "    print(tok.text)\n",
    "    print(tok.pos_)\n",
    "    print( tok.tag_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a7f33",
   "metadata": {},
   "source": [
    "# Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd8c756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ربما: \n",
      "كانت: \n",
      "أحد: \n",
      "أهم: \n",
      "التطورات: \n",
      "التي: \n",
      "قامت: \n",
      "بها: \n",
      "الرياضيات: \n",
      "العربية: \n",
      "التي: \n",
      "بدأت: \n",
      "في: \n",
      "هذا: \n",
      "الوقت: \n",
      "بعمل: \n",
      "الخوارزمي: \n",
      "و: \n",
      "هي: \n",
      "بدايات: \n",
      "الجبر: \n",
      "،: \n",
      "و: \n",
      "من: \n",
      "المهم: \n",
      "فهم: \n",
      "كيف: \n",
      "كانت: \n",
      "هذه: \n",
      "الفكرة: \n",
      "الجديدة: \n",
      "مهمة: \n",
      "،: \n",
      "فقد: \n",
      "كانت: \n",
      "خطوة: \n",
      "ثورية: \n",
      "بعيدا: \n",
      "عن: \n",
      "المفهوم: \n",
      "اليوناني: \n",
      "للرياضيات: \n",
      "التي: \n",
      "هي: \n",
      "في: \n",
      "جوهرها: \n",
      "هندسة: \n",
      "،: \n",
      "الجبر: \n",
      "كان: \n",
      "نظرية: \n",
      "موحدة: \n",
      "تتيح: \n",
      "الأعداد: \n",
      "الكسرية: \n",
      "و: \n",
      "الأعداد: \n",
      "اللا: \n",
      "كسرية: \n",
      "،: \n",
      "و: \n",
      "قدم: \n",
      "وسيلة: \n",
      "للتنمية: \n",
      "في: \n",
      "هذا: \n",
      "الموضوع: \n",
      "مستقبلا: \n",
      ".: \n",
      "و: \n",
      "جانب: \n",
      "آخر: \n",
      "مهم: \n",
      "لإدخال: \n",
      "أفكار: \n",
      "الجبر: \n",
      "و: \n",
      "هو: \n",
      "أنه: \n",
      "سمح: \n",
      "بتطبيق: \n",
      "الرياضيات: \n",
      "على: \n",
      "نفسها: \n",
      "بطريقة: \n",
      "لم: \n",
      "تحدث: \n",
      "من: \n",
      "قبل: \n"
     ]
    }
   ],
   "source": [
    "for word in txt:\n",
    "    print(word.text + ':' , word.lemma_ )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9d40e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-175bccbf33d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#sentence tokenization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "#sentence tokenization\n",
    "for s in txt.sents:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92fb99a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000027B876B5D00> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c044990432dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Add the component to the pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msbd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000027B876B5D00> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import *\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "# Create the pipeline 'sentencizer' component\n",
    "#sbd = nlp.create_pipe('sentencizer')\n",
    "\n",
    "# Add the component to the pipeline\n",
    "nlp.add_pipe(sbd)\n",
    "\n",
    "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
    "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp(text)\n",
    "\n",
    "# create list of sentence tokens\n",
    "sents_list = []\n",
    "for sent in doc.sents:\n",
    "    sents_list.append(sent.text)\n",
    "print(sents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab864f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
